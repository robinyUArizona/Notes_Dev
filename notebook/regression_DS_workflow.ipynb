{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from word2number import w2n\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from category_encoders import CountEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np  # Import numpy\n",
    "\n",
    "# Step 2: Load the Train and Test Datasets\n",
    "train_data = pd.read_csv('train.csv')  # Replace with your actual training data file\n",
    "test_data = pd.read_csv('test.csv')  # Replace with your actual test data file\n",
    "\n",
    "# Display the first few rows of the train dataset\n",
    "train_data.head()\n",
    "\n",
    "# Step 3: Define a Function to Convert Words to Numbers  (No Words in Your Data, so commenting out)\n",
    "#def convert_to_float(value):\n",
    "#    try:\n",
    "#        num = float(value)  # Convert directly if it's a number\n",
    "#    except ValueError:\n",
    "#        num = float(w2n.word_to_num(value))  # Convert word to number\n",
    "#    return abs(num)  # Remove negative sign\n",
    "\n",
    "# Step 4: Preprocess the `column` in Train and Test Data (Assuming you have a column named 'column' to split)\n",
    "# Adjust this to your actual column preprocessing\n",
    "def preprocess_column(df):\n",
    "    # If the column exists, perform the split and conversion\n",
    "    if 'column' in df.columns:\n",
    "        # Split into two columns based on multiple delimiters (;, :, ,, _)\n",
    "        df[['col1', 'col2']] = df['column'].str.split(r'[;:,_]\\s*', expand=True)\n",
    "\n",
    "        # Convert col1 and col2 values to float and remove negative signs\n",
    "        #df['col1'] = df['col1'].apply(convert_to_float) #Commented out as it caused issues for the problem\n",
    "        df['col1'] = df['col1'].astype(float).abs() #Changing this since conversion function doesn't fit problem\n",
    "        df['col2'] = df['col2'].astype(float).abs()  # Convert col2 to float and remove negative signs\n",
    "\n",
    "        # Drop the original column\n",
    "        df.drop(columns=['column'], inplace=True)\n",
    "    else:\n",
    "        print(\"'column' not found in the dataframe.  Skipping preprocessing.\")\n",
    "    return df\n",
    "\n",
    "# Preprocess the train and test datasets\n",
    "train_data = preprocess_column(train_data)\n",
    "test_data = preprocess_column(test_data)\n",
    "\n",
    "# Display the processed train dataset\n",
    "train_data.head()\n",
    "\n",
    "# Step 5: Separate Features and Target\n",
    "X_train = train_data.drop(columns=['label'])  # Assuming 'label' is the column name for the target\n",
    "y_train = train_data['label']\n",
    "\n",
    "X_test = test_data  # Drop 'label' if it exists in test_data (Test data shouldn't have label)\n",
    "\n",
    "# Display the first few rows of X_train\n",
    "X_train.head()\n",
    "\n",
    "# Step 6: Automatically Identify Numerical and Categorical Features\n",
    "numerical_features = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"Numerical Features: {numerical_features}\")\n",
    "print(f\"Categorical Features: {categorical_features}\")\n",
    "\n",
    "# Step 7: Create a Preprocessing Pipeline\n",
    "def create_column_transformer(numerical_features, categorical_features):\n",
    "    # Preprocessing for numerical features\n",
    "    num_transformer = make_pipeline(\n",
    "        SimpleImputer(strategy='median'),  # Impute missing values with median\n",
    "        RobustScaler()  # Scale numerical features\n",
    "    )\n",
    "    \n",
    "    # Preprocessing for categorical features\n",
    "    #  Frequency Encoding and OneHotEncoding are less suited for regression tasks.\n",
    "    # Consider removing/adjusting these steps based on your data.\n",
    "    if categorical_features: #added condition to ensure the function works if no categorical features exist\n",
    "        freq_encoder = CountEncoder(normalize=True)  # Frequency Encoding\n",
    "        one_hot_encoder = OneHotEncoder(handle_unknown='ignore')  # One-Hot Encoding\n",
    "\n",
    "        cat_transformer = make_column_transformer(\n",
    "            (freq_encoder, categorical_features),  # Frequency Encoding for categorical features\n",
    "            (one_hot_encoder, categorical_features),  # One-Hot Encoding for categorical features\n",
    "            remainder=\"drop\"  # Drop columns not explicitly transformed\n",
    "        )\n",
    "\n",
    "        column_transformer = make_column_transformer(\n",
    "            (num_transformer, numerical_features),  # Apply numerical transformer to numerical features\n",
    "            (cat_transformer, categorical_features),  # Apply categorical transformer to categorical features\n",
    "            remainder=\"passthrough\"  # Use passtrough to avoid dropping columns not involved in the process\n",
    "        )\n",
    "    else: # If there are no categorical features\n",
    "        column_transformer = make_column_transformer(\n",
    "        (num_transformer, numerical_features),  # Apply numerical transformer to numerical features\n",
    "        remainder=\"passthrough\"  # Use passthrough to avoid dropping columns not involved in the process\n",
    "        )\n",
    "    \n",
    "    return column_transformer\n",
    "\n",
    "# Initialize the column transformer\n",
    "column_transformer = create_column_transformer(numerical_features, categorical_features)\n",
    "\n",
    "# Step 8: Transform the Training and Test Data\n",
    "input_features_train_array = column_transformer.fit_transform(X_train)\n",
    "print(\"Encoded and Scaled Train dataset:\")\n",
    "pd.DataFrame(input_features_train_array).head()\n",
    "\n",
    "input_features_test_array = column_transformer.transform(X_test)\n",
    "print(\"Encoded and Scaled Test dataset:\")\n",
    "pd.DataFrame(input_features_test_array).head()\n",
    "\n",
    "# Step 9: Define and Evaluate Models (Changed to regression models and r2_score)\n",
    "# Choosing RandomForestRegressor as the single model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Evaluate model using cross-validation\n",
    "cv_scores = cross_val_score(model, input_features_train_array, y_train, cv=5, scoring='r2')\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(f'Random Forest Cross-Validation R2 Score: {mean_cv_score:.4f}')\n",
    "\n",
    "# Step 10: Train the Best Model and Make Predictions\n",
    "model.fit(input_features_train_array, y_train)\n",
    "\n",
    "test_predictions = model.predict(input_features_test_array)\n",
    "\n",
    "submission = pd.DataFrame({'label': test_predictions})  # Assuming label is the target\n",
    "submission.to_csv('submissions.csv', index=False)\n",
    "print(\"Submission file has been saved successfully.\")\n",
    "\n",
    "\n",
    "# Step 11: Feature Importance\n",
    "\n",
    "importances = model.feature_importances_\n",
    "features = X_train.columns\n",
    "feature_importances = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "feature_importances = feature_importances.sort_values('Importance', ascending=False).head(10) # Display top 10\n",
    "print(\"\\nFeature Importances:\")\n",
    "print(feature_importances)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importances['Feature'], feature_importances['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
